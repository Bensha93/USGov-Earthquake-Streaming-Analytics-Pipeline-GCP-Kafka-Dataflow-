[2025-10-30T20:01:18.659+0000] {processor.py:186} INFO - Started process (PID=165326) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:01:18.661+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:01:18.665+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:01:18.692+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:01:18.872+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.871+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:18.897+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.896+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:18.916+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.915+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:18.958+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.957+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:18.982+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:18.982+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:19.006+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.005+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:19.031+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.030+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_never_scheduled
[2025-10-30T20:01:19.075+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.075+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.097+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.096+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.119+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.118+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.162+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.161+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.183+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.182+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.200+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.199+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.219+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.219+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:19.261+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.260+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_consumes_1
[2025-10-30T20:01:19.285+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.284+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_consumes_1
[2025-10-30T20:01:19.309+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.309+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_consumes_1
[2025-10-30T20:01:19.350+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.349+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1
[2025-10-30T20:01:19.371+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.370+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1
[2025-10-30T20:01:19.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.389+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1
[2025-10-30T20:01:19.410+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.409+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1
[2025-10-30T20:01:19.453+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.453+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.478+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.478+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.498+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.497+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.541+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.540+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.562+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.561+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.578+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.578+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.597+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.597+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:19.647+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.646+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_produces_2
[2025-10-30T20:01:19.670+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.669+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_produces_2
[2025-10-30T20:01:19.692+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.692+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_produces_2
[2025-10-30T20:01:19.720+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.719+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_produces_2
[2025-10-30T20:01:19.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.741+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_produces_2
[2025-10-30T20:01:19.764+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.763+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_produces_2
[2025-10-30T20:01:19.783+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.783+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_produces_2
[2025-10-30T20:01:19.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.828+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.850+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.850+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.874+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.873+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.908+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.907+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.927+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.926+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.946+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.946+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:19.967+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:19.966+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:20.007+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.007+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_produces_1
[2025-10-30T20:01:20.033+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.032+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_produces_1
[2025-10-30T20:01:20.054+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.053+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_produces_1
[2025-10-30T20:01:20.091+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.090+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_produces_1
[2025-10-30T20:01:20.110+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.109+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_produces_1
[2025-10-30T20:01:20.133+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.132+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_produces_1
[2025-10-30T20:01:20.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.158+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_produces_1
[2025-10-30T20:01:20.201+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.200+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.220+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.220+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.242+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.241+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.270+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.269+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.291+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.290+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.312+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.312+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.335+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.334+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.380+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.403+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.402+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.421+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.420+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.457+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.456+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.477+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.477+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.494+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.513+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.513+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.562+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.561+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_and_2
[2025-10-30T20:01:20.583+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.582+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_consumes_1_and_2
[2025-10-30T20:01:20.604+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.603+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_and_2
[2025-10-30T20:01:20.645+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.644+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_and_2
[2025-10-30T20:01:20.668+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.667+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_and_2
[2025-10-30T20:01:20.689+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.689+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_and_2
[2025-10-30T20:01:20.709+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.708+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_and_2
[2025-10-30T20:01:20.709+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.709+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:01:20.747+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.746+0000] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_both_2_and_3_with_dataset_expressions
[2025-10-30T20:01:20.748+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.748+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2025-10-30T20:01:20.749+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.748+0000] {dag.py:3262} INFO - Creating ORM DAG for consume_1_and_2_with_dataset_expressions
[2025-10-30T20:01:20.750+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.749+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2025-10-30T20:01:20.751+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.750+0000] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_2_with_dataset_expressions
[2025-10-30T20:01:20.751+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.751+0000] {dag.py:3262} INFO - Creating ORM DAG for conditional_dataset_and_time_based_timetable
[2025-10-30T20:01:20.752+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.752+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1
[2025-10-30T20:01:20.753+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.753+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_2
[2025-10-30T20:01:20.754+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.754+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2025-10-30T20:01:20.755+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.755+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_1
[2025-10-30T20:01:20.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.769+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:01:20.770+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.770+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:01:20.771+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.771+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:01:20.772+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.772+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:01:20.772+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.772+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:01:20.773+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.773+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:01:20.775+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.774+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:01:20.776+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.775+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:01:20.778+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.778+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:01:20.779+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:20.778+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:01:20.898+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 2.247 seconds
[2025-10-30T20:02:51.977+0000] {processor.py:186} INFO - Started process (PID=165933) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:02:51.980+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:02:51.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:51.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:02:52.016+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:02:52.072+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.071+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:02:52.113+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.113+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:02:52.120+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.120+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:02:52.121+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.121+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:02:52.123+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.123+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:02:52.124+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.124+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:02:52.125+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.125+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:02:52.126+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.126+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:02:52.127+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.127+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:02:52.132+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.131+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:02:52.134+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:52.134+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:02:52.193+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.228 seconds
[2025-10-30T20:04:09.442+0000] {processor.py:186} INFO - Started process (PID=166442) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:04:09.444+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:04:09.447+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:04:09.474+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:04:09.531+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.531+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:04:09.569+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.568+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:04:09.573+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.573+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:04:09.574+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.574+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:04:09.575+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.575+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:04:09.577+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.576+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:04:09.578+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.578+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:04:09.579+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.579+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:04:09.581+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:04:09.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:04:09.587+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:09.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:04:09.635+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.203 seconds
[2025-10-30T20:05:32.918+0000] {processor.py:186} INFO - Started process (PID=167014) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:05:32.921+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:05:32.924+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:32.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:05:32.949+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:05:33.006+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.006+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:05:33.045+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.045+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:05:33.050+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.049+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:05:33.051+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.051+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:05:33.052+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.052+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:05:33.053+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.053+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:05:33.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.054+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:05:33.056+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.056+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:05:33.058+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.057+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:05:33.061+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.061+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:05:33.063+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:33.063+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:05:33.118+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.209 seconds
[2025-10-30T20:06:56.488+0000] {processor.py:186} INFO - Started process (PID=167404) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:06:56.490+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:06:56.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:06:56.519+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:06:56.578+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.577+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:06:56.614+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.614+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:06:56.621+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.620+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:06:56.622+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.622+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:06:56.623+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.623+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:06:56.624+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.624+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:06:56.625+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.625+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:06:56.626+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.626+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:06:56.628+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.627+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:06:56.631+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.631+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:06:56.633+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:06:56.632+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:06:56.682+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.205 seconds
[2025-10-30T20:08:10.881+0000] {processor.py:186} INFO - Started process (PID=169910) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:08:10.913+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:08:10.918+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:10.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:08:10.946+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:08:10.998+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:10.998+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:08:11.037+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.036+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:08:11.043+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.042+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:08:11.045+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.045+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:08:11.047+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.047+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:08:11.049+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.048+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:08:11.050+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.050+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:08:11.051+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.051+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:08:11.052+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.052+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:08:11.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.054+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:08:11.056+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:11.056+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:08:11.109+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.239 seconds
[2025-10-30T20:09:31.393+0000] {processor.py:186} INFO - Started process (PID=170230) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:09:31.430+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:09:31.434+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:09:31.461+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:09:31.528+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.528+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:09:31.581+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.581+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:09:31.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.589+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:09:31.590+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.590+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:09:31.591+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.591+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:09:31.592+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.592+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:09:31.593+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:09:31.594+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.594+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:09:31.595+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.595+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:09:31.598+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.597+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:09:31.599+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:31.599+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:09:31.661+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.277 seconds
[2025-10-30T20:10:58.844+0000] {processor.py:186} INFO - Started process (PID=170573) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:10:58.847+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:10:58.850+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:10:58.875+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:10:58.932+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.932+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:10:58.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.969+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:10:58.974+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.974+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:10:58.975+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.975+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:10:58.977+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.976+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:10:58.978+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.978+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:10:58.980+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.979+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:10:58.981+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.981+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:10:58.983+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.982+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:10:58.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.986+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:10:58.988+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:10:58.987+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:10:59.036+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.203 seconds
[2025-10-30T20:12:10.645+0000] {processor.py:186} INFO - Started process (PID=170645) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:12:10.671+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:12:10.676+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:12:10.707+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:12:10.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.769+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:12:10.808+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.808+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:12:10.814+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.813+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:12:10.815+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.815+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:12:10.816+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.816+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:12:10.817+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.817+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:12:10.818+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.818+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:12:10.819+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.819+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:12:10.820+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.820+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:12:10.824+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.824+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:12:10.826+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:10.826+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:12:10.881+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.245 seconds
[2025-10-30T20:13:23.436+0000] {processor.py:186} INFO - Started process (PID=170717) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:13:23.438+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:13:23.443+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:13:23.467+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:13:23.527+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.526+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:13:23.567+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.566+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:13:23.572+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.572+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:13:23.573+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.573+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:13:23.575+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.574+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:13:23.576+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.576+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:13:23.577+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.577+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:13:23.578+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.578+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:13:23.579+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.579+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:13:23.583+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.583+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:13:23.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:23.585+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:13:23.640+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.213 seconds
[2025-10-30T20:14:32.836+0000] {processor.py:186} INFO - Started process (PID=170787) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:14:32.839+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:14:32.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:14:32.872+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:14:32.924+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.924+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:14:32.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.968+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:14:32.974+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.974+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:14:32.977+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.977+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:14:32.979+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.979+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:14:32.981+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.980+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:14:32.982+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.982+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:14:32.983+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.983+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:14:32.984+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.984+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:14:32.987+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.987+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:14:32.988+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:32.988+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:14:33.057+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.235 seconds
[2025-10-30T20:16:02.106+0000] {processor.py:186} INFO - Started process (PID=171124) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:16:02.111+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:16:02.114+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:16:02.140+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:16:02.199+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.198+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:16:02.233+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.233+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:16:02.238+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.238+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:16:02.240+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.239+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:16:02.241+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.241+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:16:02.243+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.242+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:16:02.244+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.244+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:16:02.246+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.246+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:16:02.248+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.247+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:16:02.252+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.252+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:16:02.254+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:02.254+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:16:02.305+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.211 seconds
[2025-10-30T20:17:26.870+0000] {processor.py:186} INFO - Started process (PID=171352) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:17:26.872+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:17:26.876+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:26.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:17:26.902+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:17:26.958+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:26.957+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:17:26.996+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:26.995+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:17:27.001+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.000+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:17:27.002+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.002+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:17:27.004+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.003+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:17:27.005+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.005+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:17:27.006+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.006+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:17:27.008+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.007+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:17:27.010+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.009+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:17:27.014+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.013+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:17:27.016+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:27.015+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:17:27.068+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.211 seconds
[2025-10-30T20:19:41.078+0000] {processor.py:186} INFO - Started process (PID=171860) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:19:41.081+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:19:41.084+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:19:41.114+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:19:41.171+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.171+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:19:41.213+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.213+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:19:41.219+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.218+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:19:41.221+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.221+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:19:41.222+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.222+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:19:41.224+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.223+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:19:41.225+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.224+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:19:41.226+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.226+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:19:41.227+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.226+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:19:41.229+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.229+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:19:41.230+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:41.230+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:19:41.284+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.216 seconds
[2025-10-30T20:21:53.248+0000] {processor.py:186} INFO - Started process (PID=172915) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:21:53.261+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:21:53.265+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:21:53.292+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:21:53.347+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.346+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:21:53.386+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.385+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:21:53.393+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.392+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:21:53.395+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.395+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:21:53.397+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.396+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:21:53.398+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.398+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:21:53.399+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.399+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:21:53.400+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.400+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:21:53.401+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.401+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:21:53.403+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.403+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:21:53.405+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:53.404+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:21:53.459+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.222 seconds
[2025-10-30T20:23:21.714+0000] {processor.py:186} INFO - Started process (PID=179331) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:23:21.716+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:23:21.721+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:23:21.748+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:23:21.808+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.808+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:23:21.849+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.848+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:23:21.855+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.854+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:23:21.856+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.856+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:23:21.857+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.857+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:23:21.859+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.858+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:23:21.860+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.860+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:23:21.861+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.861+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:23:21.863+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.862+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:23:21.868+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.867+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:23:21.870+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:21.870+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:23:21.930+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.225 seconds
[2025-10-30T20:24:54.927+0000] {processor.py:186} INFO - Started process (PID=179893) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:24:54.930+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:24:54.935+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:54.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:24:54.962+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:24:55.018+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.018+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:24:55.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.055+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:24:55.062+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.062+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:24:55.064+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.063+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:24:55.065+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.065+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:24:55.066+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.066+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:24:55.067+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.067+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:24:55.068+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.068+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:24:55.070+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.069+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:24:55.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.073+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:24:55.076+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:55.075+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:24:55.123+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.206 seconds
[2025-10-30T20:27:33.065+0000] {processor.py:186} INFO - Started process (PID=192656) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:27:33.099+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:27:33.104+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:27:33.130+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:27:33.187+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.186+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:27:33.224+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.223+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:27:33.230+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.229+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:27:33.231+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.231+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:27:33.232+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.232+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:27:33.234+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.233+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:27:33.235+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.235+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:27:33.236+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.236+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:27:33.237+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.237+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:27:33.240+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.239+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:27:33.241+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:27:33.240+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:27:33.296+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.242 seconds
[2025-10-30T20:29:13.361+0000] {processor.py:186} INFO - Started process (PID=195279) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:29:13.385+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:29:13.389+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:29:13.418+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:29:13.476+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.476+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:29:13.514+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.513+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:29:13.521+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.520+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:29:13.522+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.522+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:29:13.523+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.523+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:29:13.525+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.524+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:29:13.526+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.525+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:29:13.527+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.526+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:29:13.528+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.527+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:29:13.530+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.530+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:29:13.532+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:13.531+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:29:13.586+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.236 seconds
[2025-10-30T20:31:39.250+0000] {processor.py:186} INFO - Started process (PID=195817) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:31:39.253+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:31:39.256+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:31:39.281+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:31:39.336+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.336+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:31:39.373+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.373+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:31:39.378+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.378+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:31:39.380+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.379+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:31:39.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.381+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:31:39.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.382+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:31:39.383+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.383+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:31:39.384+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:31:39.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.385+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:31:39.388+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.388+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:31:39.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:31:39.389+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:31:39.442+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.202 seconds
[2025-10-30T20:33:22.209+0000] {processor.py:186} INFO - Started process (PID=196036) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:33:22.212+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:33:22.215+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:33:22.242+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:33:22.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.302+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:33:22.339+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.339+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:33:22.343+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.343+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:33:22.345+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.344+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:33:22.346+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.346+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:33:22.348+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.347+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:33:22.349+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.349+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:33:22.351+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.350+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:33:22.352+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.352+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:33:22.356+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.356+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:33:22.358+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:22.358+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:33:22.405+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.207 seconds
[2025-10-30T20:34:54.234+0000] {processor.py:186} INFO - Started process (PID=196261) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:34:54.236+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:34:54.240+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:34:54.266+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:34:54.326+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.326+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:34:54.363+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.362+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:34:54.369+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.369+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:34:54.371+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.371+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:34:54.373+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.373+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:34:54.374+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.374+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:34:54.375+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.375+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:34:54.377+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.376+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:34:54.378+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.378+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:34:54.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.381+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:34:54.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:34:54.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:34:54.439+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.217 seconds
[2025-10-30T20:37:24.964+0000] {processor.py:186} INFO - Started process (PID=196914) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:37:24.966+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:37:24.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:24.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:37:25.001+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:37:25.060+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.059+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:37:25.097+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.096+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:37:25.102+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.102+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:37:25.105+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.104+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:37:25.107+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.106+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:37:25.109+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.108+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:37:25.111+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.110+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:37:25.112+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.112+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:37:25.114+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.114+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:37:25.118+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.117+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:37:25.119+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:37:25.119+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:37:25.179+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.225 seconds
[2025-10-30T20:39:03.396+0000] {processor.py:186} INFO - Started process (PID=197149) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:39:03.399+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:39:03.402+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:39:03.430+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:39:03.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.493+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:39:03.532+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.532+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:39:03.537+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.536+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:39:03.539+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.539+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:39:03.541+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.540+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:39:03.543+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.542+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:39:03.545+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.544+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:39:03.547+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.547+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:39:03.549+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.549+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:39:03.552+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.551+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:39:03.553+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:03.553+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:39:03.607+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.222 seconds
[2025-10-30T20:40:56.867+0000] {processor.py:186} INFO - Started process (PID=199805) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:40:56.869+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:40:56.873+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:56.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:40:56.900+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:40:56.961+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:56.961+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:40:57.001+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.001+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:40:57.006+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.005+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:40:57.008+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.008+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:40:57.011+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.010+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:40:57.013+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.012+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:40:57.015+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.014+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:40:57.016+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.016+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:40:57.018+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.018+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:40:57.023+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.022+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:40:57.025+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:40:57.024+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:40:57.087+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.230 seconds
[2025-10-30T20:42:18.893+0000] {processor.py:186} INFO - Started process (PID=200015) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:42:18.896+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:42:18.900+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:18.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:42:18.926+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:42:18.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:18.985+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:42:19.025+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.025+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:42:19.030+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.030+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:42:19.033+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.032+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:42:19.035+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.034+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:42:19.036+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.036+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:42:19.038+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.038+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:42:19.040+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.040+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:42:19.042+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.041+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:42:19.044+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.044+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:42:19.045+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:19.045+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:42:19.096+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.212 seconds
[2025-10-30T20:43:39.784+0000] {processor.py:186} INFO - Started process (PID=200156) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:43:39.786+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:43:39.790+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:43:39.816+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:43:39.867+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.867+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:43:39.905+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.905+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:43:39.910+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.910+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:43:39.911+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.911+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:43:39.913+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.912+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:43:39.914+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.914+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:43:39.916+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.915+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:43:39.917+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.917+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:43:39.919+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.918+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:43:39.922+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.922+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:43:39.924+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:43:39.924+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:43:39.982+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.208 seconds
[2025-10-30T20:44:53.219+0000] {processor.py:186} INFO - Started process (PID=200267) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:44:53.240+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:44:53.245+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:44:53.271+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:44:53.329+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.328+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:44:53.366+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.366+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:44:53.372+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.372+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:44:53.376+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.375+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:44:53.377+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.377+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:44:53.378+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.378+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:44:53.379+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.379+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:44:53.380+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.380+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:44:53.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.381+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:44:53.384+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:44:53.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:53.385+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:44:53.439+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.229 seconds
[2025-10-30T20:46:33.936+0000] {processor.py:186} INFO - Started process (PID=200511) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:46:33.939+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:46:33.944+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:33.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:46:33.972+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:46:34.034+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.033+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:46:34.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.073+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:46:34.081+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.081+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:46:34.083+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.083+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:46:34.084+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.084+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:46:34.085+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.085+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:46:34.086+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.086+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:46:34.087+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.087+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:46:34.088+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.088+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:46:34.091+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.090+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:46:34.092+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:46:34.092+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:46:34.161+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.236 seconds
[2025-10-30T20:47:54.300+0000] {processor.py:186} INFO - Started process (PID=200648) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:47:54.311+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:47:54.315+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:47:54.341+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:47:54.393+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.393+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:47:54.428+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.428+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:47:54.434+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.434+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:47:54.437+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.437+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:47:54.439+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.439+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:47:54.440+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.440+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:47:54.441+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.441+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:47:54.442+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.442+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:47:54.443+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.443+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:47:54.445+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:47:54.446+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:54.446+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:47:54.503+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.211 seconds
[2025-10-30T20:49:16.185+0000] {processor.py:186} INFO - Started process (PID=200747) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:49:16.188+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:49:16.191+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:49:16.217+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:49:16.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.276+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:49:16.316+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.316+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:49:16.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.320+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:49:16.322+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.322+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:49:16.324+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.323+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:49:16.325+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.325+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:49:16.326+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.326+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:49:16.328+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.328+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:49:16.329+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.329+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:49:16.333+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.333+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:49:16.335+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:16.334+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:49:16.385+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.212 seconds
[2025-10-30T20:50:54.577+0000] {processor.py:186} INFO - Started process (PID=200990) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:50:54.612+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:50:54.616+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:50:54.642+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:50:54.696+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.696+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:50:54.733+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.733+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:50:54.739+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.739+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:50:54.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.741+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:50:54.743+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.743+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:50:54.745+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.745+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:50:54.746+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.746+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:50:54.747+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.747+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:50:54.748+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:50:54.752+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.752+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:50:54.754+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:50:54.753+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:50:54.808+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.239 seconds
[2025-10-30T20:52:11.300+0000] {processor.py:186} INFO - Started process (PID=201064) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:52:11.323+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:52:11.327+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:52:11.353+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:52:11.409+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.408+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:52:11.446+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.446+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:52:11.453+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.453+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:52:11.455+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.455+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:52:11.456+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.456+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:52:11.457+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.457+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:52:11.458+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.458+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:52:11.459+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.459+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:52:11.460+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.460+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:52:11.462+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.462+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:52:11.463+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:11.463+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:52:11.512+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.221 seconds
[2025-10-30T20:53:32.199+0000] {processor.py:186} INFO - Started process (PID=201207) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:53:32.202+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:53:32.205+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:53:32.227+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:53:32.268+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.268+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:53:32.298+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.297+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:53:32.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.301+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:53:32.303+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.303+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:53:32.304+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.304+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:53:32.305+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.305+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:53:32.306+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.306+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:53:32.307+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.307+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:53:32.308+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.308+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:53:32.310+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.310+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:53:32.311+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:32.311+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:53:32.353+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.163 seconds
[2025-10-30T20:54:50.362+0000] {processor.py:186} INFO - Started process (PID=201298) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:54:50.365+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:54:50.368+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:54:50.389+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:54:50.432+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.432+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:54:50.464+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.463+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:54:50.468+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.468+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:54:50.470+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.469+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:54:50.471+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.471+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:54:50.472+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.472+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:54:50.473+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.473+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:54:50.474+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.474+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:54:50.475+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.475+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:54:50.477+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.477+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:54:50.478+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:54:50.478+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:54:50.525+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.171 seconds
[2025-10-30T20:56:27.554+0000] {processor.py:186} INFO - Started process (PID=201527) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:56:27.556+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:56:27.560+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:56:27.581+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:56:27.629+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.628+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:56:27.659+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.659+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:56:27.663+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.663+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:56:27.665+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.665+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:56:27.666+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.666+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:56:27.667+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.667+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:56:27.669+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.668+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:56:27.670+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.669+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:56:27.671+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.671+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:56:27.673+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.673+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:56:27.674+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:27.674+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:56:27.718+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.173 seconds
[2025-10-30T20:57:39.459+0000] {processor.py:186} INFO - Started process (PID=201600) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:57:39.461+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:57:39.465+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:57:39.488+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:57:39.537+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.537+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:57:39.569+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.569+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:57:39.575+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.575+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:57:39.577+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.577+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:57:39.579+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.578+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:57:39.580+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.580+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:57:39.581+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:57:39.582+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.582+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:57:39.583+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.583+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:57:39.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.585+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:57:39.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:57:39.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:57:39.628+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.178 seconds
[2025-10-30T20:58:48.181+0000] {processor.py:186} INFO - Started process (PID=201687) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:58:48.184+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:58:48.187+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:58:48.210+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:58:48.256+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.256+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:58:48.287+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.287+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:58:48.291+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.291+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:58:48.295+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.294+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:58:48.296+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.296+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:58:48.297+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.297+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:58:48.298+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.298+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:58:48.299+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.299+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:58:48.300+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.300+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:58:48.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.302+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:58:48.303+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:48.303+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:58:48.348+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.174 seconds
[2025-10-30T20:59:56.505+0000] {processor.py:186} INFO - Started process (PID=201757) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:59:56.507+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T20:59:56.511+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:59:56.533+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T20:59:56.579+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.579+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T20:59:56.610+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.610+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T20:59:56.614+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.614+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:59:56.616+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.615+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T20:59:56.617+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.617+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T20:59:56.618+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.618+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T20:59:56.619+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.619+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T20:59:56.620+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.620+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T20:59:56.621+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.621+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T20:59:56.623+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.623+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T20:59:56.624+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:56.624+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T20:59:56.670+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.173 seconds
[2025-10-30T21:01:22.683+0000] {processor.py:186} INFO - Started process (PID=201984) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:01:22.685+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:01:22.689+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:01:22.711+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:01:22.790+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.790+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:01:22.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.828+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:01:22.833+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.833+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:01:22.835+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.835+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:01:22.836+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.836+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:01:22.837+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.837+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:01:22.838+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.838+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:01:22.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.839+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:01:22.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.840+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:01:22.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.843+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:01:22.845+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:22.844+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:01:22.889+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.215 seconds
[2025-10-30T21:02:35.240+0000] {processor.py:186} INFO - Started process (PID=202055) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:02:35.279+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:02:35.283+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:02:35.303+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:02:35.345+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.345+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:02:35.376+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.375+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:02:35.380+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.379+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:02:35.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.381+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:02:35.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.382+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:02:35.383+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.383+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:02:35.384+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:02:35.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.385+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:02:35.386+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.386+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:02:35.389+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.388+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:02:35.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:35.389+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:02:35.432+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.199 seconds
[2025-10-30T21:03:44.072+0000] {processor.py:186} INFO - Started process (PID=202145) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:03:44.074+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:03:44.078+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:03:44.101+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:03:44.145+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.145+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:03:44.176+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.176+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:03:44.181+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.180+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:03:44.182+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.182+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:03:44.183+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.183+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:03:44.185+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.184+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:03:44.186+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.186+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:03:44.187+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.187+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:03:44.188+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.188+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:03:44.190+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.190+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:03:44.192+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:44.191+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:03:44.235+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:04:52.391+0000] {processor.py:186} INFO - Started process (PID=202214) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:04:52.393+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:04:52.396+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:04:52.417+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:04:52.459+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.459+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:04:52.490+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.489+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:04:52.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.494+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:04:52.497+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.497+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:04:52.498+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.498+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:04:52.499+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.499+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:04:52.500+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.500+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:04:52.501+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.501+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:04:52.502+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.502+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:04:52.504+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.504+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:04:52.505+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:52.505+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:04:52.547+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.165 seconds
[2025-10-30T21:06:20.678+0000] {processor.py:186} INFO - Started process (PID=202435) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:06:20.681+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:06:20.685+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:06:20.706+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:06:20.752+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.752+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:06:20.782+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.781+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:06:20.786+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.786+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:06:20.788+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.787+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:06:20.789+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.788+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:06:20.790+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.789+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:06:20.791+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.790+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:06:20.792+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.791+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:06:20.793+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.792+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:06:20.795+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.795+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:06:20.796+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:20.796+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:06:20.841+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:07:27.441+0000] {processor.py:186} INFO - Started process (PID=202504) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:07:27.444+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:07:27.448+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:07:27.469+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:07:27.512+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.512+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:07:27.544+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.543+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:07:27.548+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.548+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:07:27.550+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.549+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:07:27.551+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.551+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:07:27.552+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.552+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:07:27.553+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.553+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:07:27.554+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.554+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:07:27.555+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.554+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:07:27.557+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.557+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:07:27.558+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:27.558+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:07:27.600+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.167 seconds
[2025-10-30T21:08:42.854+0000] {processor.py:186} INFO - Started process (PID=202587) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:08:42.856+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:08:42.860+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:08:42.883+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:08:42.930+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.929+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:08:42.961+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.961+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:08:42.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.966+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:08:42.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.967+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:08:42.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.969+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:08:42.970+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.970+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:08:42.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.971+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:08:42.972+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.972+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:08:42.973+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.973+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:08:42.975+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.975+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:08:42.977+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:08:42.976+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:08:43.019+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.176 seconds
[2025-10-30T21:09:55.833+0000] {processor.py:186} INFO - Started process (PID=202668) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:09:55.835+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:09:55.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:09:55.861+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:09:55.903+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.903+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:09:55.934+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.934+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:09:55.938+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.938+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:09:55.940+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.940+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:09:55.941+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.941+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:09:55.942+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.942+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:09:55.943+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.943+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:09:55.944+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.943+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:09:55.945+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.944+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:09:55.947+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.947+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:09:55.948+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:55.948+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:09:55.989+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.165 seconds
[2025-10-30T21:11:21.693+0000] {processor.py:186} INFO - Started process (PID=202879) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:11:21.711+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:11:21.715+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:11:21.740+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:11:21.783+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.782+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:11:21.813+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.813+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:11:21.820+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.819+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:11:21.823+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.823+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:11:21.825+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.825+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:11:21.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.827+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:11:21.830+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.830+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:11:21.832+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.832+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:11:21.834+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.834+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:11:21.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.839+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:11:21.841+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:21.841+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:11:21.915+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.230 seconds
[2025-10-30T21:12:32.883+0000] {processor.py:186} INFO - Started process (PID=202951) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:12:32.920+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:12:32.923+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:32.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:12:32.946+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:12:32.990+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:32.989+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:12:33.021+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.021+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:12:33.025+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.025+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:12:33.027+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.027+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:12:33.028+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.028+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:12:33.029+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.029+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:12:33.030+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.030+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:12:33.031+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.031+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:12:33.032+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.032+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:12:33.034+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.034+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:12:33.035+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:33.035+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:12:33.077+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.202 seconds
[2025-10-30T21:13:46.833+0000] {processor.py:186} INFO - Started process (PID=203045) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:13:46.835+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:13:46.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:13:46.861+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:13:46.907+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.906+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:13:46.937+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.937+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:13:46.942+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.942+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:13:46.946+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.946+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:13:46.947+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.947+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:13:46.948+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.948+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:13:46.949+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.949+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:13:46.950+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.950+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:13:46.951+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.951+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:13:46.954+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.954+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:13:46.956+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:13:46.956+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:13:47.004+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.180 seconds
[2025-10-30T21:14:55.516+0000] {processor.py:186} INFO - Started process (PID=203115) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:14:55.518+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:14:55.521+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:14:55.544+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:14:55.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.589+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:14:55.619+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.619+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:14:55.624+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.623+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:14:55.625+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.625+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:14:55.626+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.626+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:14:55.627+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.627+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:14:55.628+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.628+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:14:55.630+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.629+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:14:55.631+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.631+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:14:55.633+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.633+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:14:55.634+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:55.634+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:14:55.677+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.170 seconds
[2025-10-30T21:16:22.482+0000] {processor.py:186} INFO - Started process (PID=203336) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:16:22.484+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:16:22.488+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:16:22.509+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:16:22.555+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.555+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:16:22.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.585+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:16:22.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.589+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:16:22.591+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.591+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:16:22.592+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.592+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:16:22.593+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:16:22.594+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.594+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:16:22.595+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.595+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:16:22.596+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.596+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:16:22.598+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.598+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:16:22.599+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:22.599+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:16:22.640+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.166 seconds
[2025-10-30T21:17:28.606+0000] {processor.py:186} INFO - Started process (PID=203406) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:17:28.609+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:17:28.612+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:17:28.634+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:17:28.680+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.680+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:17:28.713+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.713+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:17:28.717+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.717+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:17:28.719+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.719+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:17:28.721+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.721+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:17:28.722+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.722+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:17:28.723+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.723+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:17:28.724+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.724+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:17:28.725+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.725+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:17:28.727+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.727+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:17:28.729+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:28.728+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:17:28.771+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.173 seconds
[2025-10-30T21:18:43.108+0000] {processor.py:186} INFO - Started process (PID=203482) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:18:43.110+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:18:43.114+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:18:43.136+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:18:43.182+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.182+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:18:43.215+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.214+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:18:43.219+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.219+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:18:43.221+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.221+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:18:43.222+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.222+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:18:43.223+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.223+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:18:43.224+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.224+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:18:43.225+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.225+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:18:43.227+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.227+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:18:43.229+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.229+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:18:43.231+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:18:43.230+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:18:43.274+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.175 seconds
[2025-10-30T21:19:52.843+0000] {processor.py:186} INFO - Started process (PID=203569) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:19:52.878+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:19:52.882+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:19:52.904+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:19:52.947+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.947+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:19:52.977+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.976+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:19:52.981+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.980+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:19:52.982+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.982+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:19:52.983+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.983+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:19:52.984+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.984+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:19:52.985+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.985+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:19:52.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.986+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:19:52.987+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.987+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:19:52.989+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.989+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:19:52.990+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:52.990+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:19:53.032+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.198 seconds
[2025-10-30T21:21:22.448+0000] {processor.py:186} INFO - Started process (PID=203797) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:21:22.451+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:21:22.454+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:21:22.477+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:21:22.523+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.523+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:21:22.556+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.556+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:21:22.561+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.561+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:21:22.563+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.562+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:21:22.564+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.564+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:21:22.565+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.565+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:21:22.566+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.566+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:21:22.567+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.567+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:21:22.568+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.568+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:21:22.570+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.570+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:21:22.571+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:22.571+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:21:22.615+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.175 seconds
[2025-10-30T21:22:32.981+0000] {processor.py:186} INFO - Started process (PID=203867) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:22:32.984+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:22:32.987+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:32.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:22:33.010+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:22:33.060+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.060+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:22:33.092+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.092+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:22:33.097+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.096+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:22:33.099+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.098+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:22:33.100+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.100+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:22:33.101+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.101+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:22:33.102+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.102+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:22:33.103+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.103+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:22:33.104+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.104+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:22:33.106+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.106+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:22:33.107+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:33.107+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:22:33.155+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.181 seconds
[2025-10-30T21:23:48.270+0000] {processor.py:186} INFO - Started process (PID=203962) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:23:48.273+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:23:48.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:23:48.300+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:23:48.344+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.344+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:23:48.374+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.374+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:23:48.379+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.379+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:23:48.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.380+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:23:48.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.382+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:23:48.383+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.383+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:23:48.384+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:23:48.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.385+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:23:48.386+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.386+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:23:48.388+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.388+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:23:48.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:48.389+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:23:48.433+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:24:56.487+0000] {processor.py:186} INFO - Started process (PID=204032) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:24:56.490+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:24:56.493+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:24:56.517+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:24:56.569+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.568+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:24:56.603+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.602+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:24:56.607+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.607+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:24:56.609+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.609+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:24:56.610+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.610+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:24:56.612+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.611+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:24:56.613+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.613+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:24:56.614+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.614+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:24:56.615+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.615+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:24:56.617+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.617+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:24:56.618+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:56.618+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:24:56.662+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.183 seconds
[2025-10-30T21:26:30.598+0000] {processor.py:186} INFO - Started process (PID=204256) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:26:30.624+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:26:30.629+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:26:30.651+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:26:30.699+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.699+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:26:30.731+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.731+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:26:30.736+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.736+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:26:30.738+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.738+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:26:30.740+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.739+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:26:30.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.741+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:26:30.742+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.742+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:26:30.744+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.743+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:26:30.745+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.745+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:26:30.747+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.747+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:26:30.749+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:30.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:26:30.790+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.200 seconds
[2025-10-30T21:27:42.196+0000] {processor.py:186} INFO - Started process (PID=204327) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:27:42.199+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:27:42.202+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:27:42.224+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:27:42.274+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.274+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:27:42.306+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.305+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:27:42.310+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.310+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:27:42.312+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.312+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:27:42.313+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.313+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:27:42.314+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.314+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:27:42.315+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.315+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:27:42.316+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.316+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:27:42.317+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.317+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:27:42.320+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.319+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:27:42.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:27:42.320+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:27:42.363+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.176 seconds
[2025-10-30T21:28:50.551+0000] {processor.py:186} INFO - Started process (PID=204415) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:28:50.554+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:28:50.557+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:28:50.581+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:28:50.626+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.625+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:28:50.657+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.657+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:28:50.661+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.661+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:28:50.663+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.662+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:28:50.664+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.664+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:28:50.665+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.665+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:28:50.666+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.666+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:28:50.667+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.667+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:28:50.668+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.668+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:28:50.670+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.670+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:28:50.671+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:50.671+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:28:50.716+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.174 seconds
[2025-10-30T21:29:57.891+0000] {processor.py:186} INFO - Started process (PID=204483) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:29:57.893+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:29:57.897+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:57.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:29:57.919+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:29:57.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:57.966+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:29:57.997+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:57.996+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:29:58.001+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.001+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:29:58.005+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.004+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:29:58.007+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.007+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:29:58.009+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.009+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:29:58.011+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.011+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:29:58.012+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.012+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:29:58.013+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.013+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:29:58.016+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.016+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:29:58.017+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:58.017+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:29:58.061+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.179 seconds
[2025-10-30T21:31:24.043+0000] {processor.py:186} INFO - Started process (PID=204704) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:31:24.045+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:31:24.049+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:31:24.070+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:31:24.117+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.117+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:31:24.148+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.147+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:31:24.152+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.152+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:31:24.154+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.153+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:31:24.155+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.155+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:31:24.156+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.156+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:31:24.157+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.157+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:31:24.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.158+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:31:24.159+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.159+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:31:24.161+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.161+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:31:24.162+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:24.162+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:31:24.207+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:32:37.069+0000] {processor.py:186} INFO - Started process (PID=204777) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:32:37.072+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:32:37.075+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:32:37.097+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:32:37.142+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.142+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:32:37.172+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.171+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:32:37.178+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.177+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:32:37.180+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.180+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:32:37.182+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.182+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:32:37.183+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.183+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:32:37.184+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.184+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:32:37.185+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.185+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:32:37.186+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.186+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:32:37.189+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.188+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:32:37.190+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:32:37.189+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:32:37.233+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.171 seconds
[2025-10-30T21:33:47.579+0000] {processor.py:186} INFO - Started process (PID=204866) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:33:47.595+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:33:47.599+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:33:47.620+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:33:47.670+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.669+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:33:47.701+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.701+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:33:47.706+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.705+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:33:47.707+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.707+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:33:47.709+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.709+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:33:47.710+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.710+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:33:47.711+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.711+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:33:47.712+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.712+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:33:47.713+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.713+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:33:47.715+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.715+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:33:47.717+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:47.716+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:33:47.758+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.188 seconds
[2025-10-30T21:34:53.276+0000] {processor.py:186} INFO - Started process (PID=204935) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:34:53.279+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:34:53.282+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:34:53.305+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:34:53.351+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.351+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:34:53.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.385+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:34:53.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.389+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:34:53.391+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.391+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:34:53.392+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.392+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:34:53.393+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.393+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:34:53.394+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.394+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:34:53.395+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.395+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:34:53.396+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.396+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:34:53.399+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.398+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:34:53.400+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:53.399+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:34:53.444+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2025-10-30T21:36:26.771+0000] {processor.py:186} INFO - Started process (PID=205224) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:36:26.774+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:36:26.777+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:36:26.799+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:36:26.850+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.850+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:36:26.884+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.883+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:36:26.888+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.888+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:36:26.890+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.890+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:36:26.891+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.891+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:36:26.892+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.892+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:36:26.894+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.893+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:36:26.895+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.894+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:36:26.896+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.895+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:36:26.898+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.898+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:36:26.900+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:26.900+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:36:26.949+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.186 seconds
[2025-10-30T21:37:40.213+0000] {processor.py:186} INFO - Started process (PID=205297) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:37:40.216+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:37:40.219+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:37:40.241+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:37:40.287+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.287+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:37:40.316+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.316+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:37:40.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.320+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:37:40.322+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.322+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:37:40.324+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.323+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:37:40.325+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.325+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:37:40.326+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.326+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:37:40.327+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.327+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:37:40.328+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.328+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:37:40.330+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.330+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:37:40.331+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:37:40.331+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:37:40.376+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:38:45.061+0000] {processor.py:186} INFO - Started process (PID=205373) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:38:45.063+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:38:45.066+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:38:45.088+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:38:45.133+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.132+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:38:45.163+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.163+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:38:45.167+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.167+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:38:45.169+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.169+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:38:45.170+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.170+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:38:45.171+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.171+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:38:45.172+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.172+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:38:45.173+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.173+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:38:45.174+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.174+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:38:45.176+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.176+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:38:45.177+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:45.177+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:38:45.224+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2025-10-30T21:40:00.225+0000] {processor.py:186} INFO - Started process (PID=205455) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:40:00.228+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:40:00.231+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:40:00.256+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:40:00.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.301+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:40:00.333+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.333+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:40:00.338+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.338+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:40:00.340+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.340+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:40:00.341+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.341+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:40:00.343+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.342+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:40:00.344+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.344+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:40:00.345+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.345+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:40:00.346+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.346+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:40:00.349+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.348+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:40:00.350+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:00.350+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:40:00.399+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.181 seconds
[2025-10-30T21:41:24.838+0000] {processor.py:186} INFO - Started process (PID=205663) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:41:24.840+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:41:24.844+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:41:24.866+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:41:24.911+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.911+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:41:24.941+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.940+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:41:24.945+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.945+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:41:24.947+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.946+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:41:24.948+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.948+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:41:24.949+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.949+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:41:24.950+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.950+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:41:24.951+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.951+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:41:24.952+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.951+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:41:24.954+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.954+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:41:24.955+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:24.955+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:41:24.997+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.169 seconds
[2025-10-30T21:42:33.588+0000] {processor.py:186} INFO - Started process (PID=205733) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:42:33.620+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:42:33.623+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:42:33.645+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:42:33.695+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.694+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:42:33.728+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.728+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:42:33.733+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.733+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:42:33.735+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.735+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:42:33.737+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.736+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:42:33.738+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.738+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:42:33.740+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.739+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:42:33.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.741+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:42:33.742+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.742+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:42:33.744+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.744+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:42:33.746+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:33.746+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:42:33.790+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.211 seconds
[2025-10-30T21:43:44.835+0000] {processor.py:186} INFO - Started process (PID=205815) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:43:44.838+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:43:44.841+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:43:44.862+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:43:44.912+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.912+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:43:44.950+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.949+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:43:44.954+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.954+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:43:44.956+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.956+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:43:44.958+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.958+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:43:44.959+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.959+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:43:44.960+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.960+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:43:44.961+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.961+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:43:44.962+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.962+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:43:44.965+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.965+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:43:44.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:44.966+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:43:45.010+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.183 seconds
[2025-10-30T21:44:52.187+0000] {processor.py:186} INFO - Started process (PID=205892) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:44:52.189+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:44:52.193+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:44:52.215+0000] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:44:52.262+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.262+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:44:52.295+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.294+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:44:52.299+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.299+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:44:52.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.302+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:44:52.303+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.303+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:44:52.305+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.304+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:44:52.306+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.305+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:44:52.307+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.306+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:44:52.308+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.307+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:44:52.310+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.310+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:44:52.311+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:52.311+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:44:52.354+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2025-10-30T21:46:22.324+0000] {processor.py:186} INFO - Started process (PID=206082) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:46:22.327+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:46:22.330+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:46:22.353+0000] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:46:22.403+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.402+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:46:22.433+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.432+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:46:22.437+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.436+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:46:22.438+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.438+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:46:22.439+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.439+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:46:22.440+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.440+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:46:22.441+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.441+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:46:22.442+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.442+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:46:22.443+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.443+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:46:22.446+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:46:22.447+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:22.446+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:46:22.491+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.175 seconds
[2025-10-30T21:47:30.955+0000] {processor.py:186} INFO - Started process (PID=206152) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:47:30.958+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:47:30.961+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:30.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:47:30.984+0000] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:47:31.028+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.028+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:47:31.059+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.058+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:47:31.063+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.063+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:47:31.065+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.064+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:47:31.066+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.066+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:47:31.067+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.067+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:47:31.068+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.068+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:47:31.069+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.069+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:47:31.070+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.070+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:47:31.073+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.073+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:47:31.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:31.074+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:47:31.116+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.170 seconds
[2025-10-30T21:48:46.129+0000] {processor.py:186} INFO - Started process (PID=206223) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:48:46.132+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:48:46.136+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:48:46.160+0000] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:48:46.206+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.206+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:48:46.237+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.237+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:48:46.242+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.241+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:48:46.243+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.243+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:48:46.245+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.244+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:48:46.246+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.246+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:48:46.247+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.247+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:48:46.248+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.248+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:48:46.249+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.249+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:48:46.251+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.251+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:48:46.252+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:48:46.252+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:48:46.297+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2025-10-30T21:49:59.150+0000] {processor.py:186} INFO - Started process (PID=206298) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:49:59.153+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-10-30T21:49:59.156+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:49:59.179+0000] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py
[2025-10-30T21:49:59.225+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.224+0000] {dag.py:3239} INFO - Sync 10 DAGs
[2025-10-30T21:49:59.255+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.254+0000] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-10-29 01:00:00+00:00, run_after=2025-10-29 01:00:00+00:00
[2025-10-30T21:49:59.259+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.259+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:49:59.261+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.261+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-10-30T21:49:59.262+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.262+0000] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-10-30T21:49:59.263+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.263+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-10-30T21:49:59.264+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.264+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-10-30T21:49:59.265+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.265+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-10-30T21:49:59.266+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.266+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-10-30T21:49:59.268+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.268+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T21:49:59.269+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:59.269+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-10-30T21:49:59.312+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_datasets.py took 0.171 seconds
