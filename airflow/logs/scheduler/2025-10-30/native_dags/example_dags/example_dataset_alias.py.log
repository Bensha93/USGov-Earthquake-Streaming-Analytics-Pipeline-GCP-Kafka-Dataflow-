[2025-10-30T20:01:25.892+0000] {processor.py:186} INFO - Started process (PID=165394) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:01:25.894+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:01:25.897+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:25.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:01:25.931+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:01:26.111+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.110+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer
[2025-10-30T20:01:26.135+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.134+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer
[2025-10-30T20:01:26.155+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.154+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer
[2025-10-30T20:01:26.188+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.187+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer
[2025-10-30T20:01:26.208+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.207+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer
[2025-10-30T20:01:26.224+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.223+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer
[2025-10-30T20:01:26.241+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.241+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer
[2025-10-30T20:01:26.280+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.279+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.300+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.299+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.321+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.355+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.354+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.377+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.376+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.393+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.392+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.411+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.410+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.452+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.451+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.471+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.471+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.491+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.490+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.521+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.520+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.539+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.538+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.557+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.557+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.580+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.580+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer
[2025-10-30T20:01:26.628+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.627+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.647+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.646+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.669+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.668+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.703+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.703+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.724+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.723+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.743+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.742+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.759+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.758+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer
[2025-10-30T20:01:26.760+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.759+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:01:26.780+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.779+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2025-10-30T20:01:26.781+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.780+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2025-10-30T20:01:26.782+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.781+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2025-10-30T20:01:26.783+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.782+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2025-10-30T20:01:26.794+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.794+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:01:26.795+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.795+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:01:26.795+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.795+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:01:26.796+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:26.796+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:01:26.852+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.969 seconds
[2025-10-30T20:02:55.834+0000] {processor.py:186} INFO - Started process (PID=165965) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:02:55.855+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:02:55.859+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:02:55.902+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:02:55.931+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.931+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:02:55.965+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.965+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:02:55.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:02:55.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.969+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:02:55.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:55.970+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:02:56.014+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.191 seconds
[2025-10-30T20:04:12.991+0000] {processor.py:186} INFO - Started process (PID=166457) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:04:12.994+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:04:12.997+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:12.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:04:13.036+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:04:13.065+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:13.064+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:04:13.094+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:13.094+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:04:13.097+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:13.097+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:04:13.098+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:13.098+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:04:13.099+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:13.099+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:04:13.139+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.157 seconds
[2025-10-30T20:05:36.949+0000] {processor.py:186} INFO - Started process (PID=167019) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:05:36.978+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:05:36.982+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:36.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:05:37.026+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:05:37.058+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:37.058+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:05:37.093+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:37.093+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:05:37.096+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:37.096+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:05:37.098+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:37.097+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:05:37.099+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:37.099+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:05:37.146+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.207 seconds
[2025-10-30T20:07:21.024+0000] {processor.py:186} INFO - Started process (PID=167455) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:07:21.027+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:07:21.030+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:07:21.074+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:07:21.106+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.106+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:07:21.137+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.137+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:07:21.140+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:07:21.142+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.142+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:07:21.143+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:21.143+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:07:21.187+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.173 seconds
[2025-10-30T20:08:39.265+0000] {processor.py:186} INFO - Started process (PID=170057) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:08:39.268+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:08:39.272+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:08:39.310+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:08:39.343+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.343+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:08:39.373+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.373+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:08:39.376+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.376+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:08:39.378+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.378+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:08:39.380+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:39.380+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:08:39.422+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.166 seconds
[2025-10-30T20:09:57.612+0000] {processor.py:186} INFO - Started process (PID=170390) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:09:57.614+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:09:57.617+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:09:57.656+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:09:57.691+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.690+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:09:57.720+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.720+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:09:57.723+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.723+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:09:57.725+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.725+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:09:57.728+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.727+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:09:57.769+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.166 seconds
[2025-10-30T20:11:23.630+0000] {processor.py:186} INFO - Started process (PID=170597) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:11:23.633+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:11:23.637+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:11:23.678+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:11:23.713+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.713+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:11:23.748+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:11:23.752+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.752+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:11:23.754+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.753+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:11:23.755+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:23.755+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:11:23.798+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.176 seconds
[2025-10-30T20:12:34.455+0000] {processor.py:186} INFO - Started process (PID=170668) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:12:34.518+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:12:34.521+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:12:34.561+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:12:34.590+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.590+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:12:34.622+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.622+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:12:34.625+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.625+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:12:34.626+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.626+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:12:34.628+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:34.627+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:12:34.681+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.234 seconds
[2025-10-30T20:13:47.966+0000] {processor.py:186} INFO - Started process (PID=170741) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:13:47.968+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:13:47.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:47.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:13:48.014+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:13:48.047+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:48.046+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:13:48.082+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:48.082+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:13:48.085+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:48.085+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:13:48.087+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:48.087+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:13:48.090+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:48.089+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:13:48.135+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.180 seconds
[2025-10-30T20:14:56.420+0000] {processor.py:186} INFO - Started process (PID=170812) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:14:56.423+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:14:56.427+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.426+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:14:56.471+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:14:56.500+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.499+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:14:56.534+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.533+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:14:56.538+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.537+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:14:56.539+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.539+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:14:56.541+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:56.541+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:14:56.588+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.177 seconds
[2025-10-30T20:16:36.144+0000] {processor.py:186} INFO - Started process (PID=171304) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:16:36.147+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:16:36.150+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:16:36.189+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:16:36.221+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.221+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:16:36.252+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.251+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:16:36.255+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.255+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:16:36.257+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.257+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:16:36.259+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:36.259+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:16:36.305+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.174 seconds
[2025-10-30T20:17:54.366+0000] {processor.py:186} INFO - Started process (PID=171379) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:17:54.369+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:17:54.373+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:17:54.411+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:17:54.445+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.445+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:17:54.481+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.480+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:17:54.485+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.485+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:17:54.487+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.487+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:17:54.488+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:54.488+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:17:54.530+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.176 seconds
[2025-10-30T20:19:44.701+0000] {processor.py:186} INFO - Started process (PID=171863) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:19:44.704+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:19:44.708+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:19:44.746+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:19:44.780+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.780+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:19:44.809+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.809+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:19:44.812+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.812+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:19:44.814+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.814+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:19:44.816+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:44.815+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:19:44.857+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.163 seconds
[2025-10-30T20:21:57.367+0000] {processor.py:186} INFO - Started process (PID=172918) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:21:57.370+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:21:57.374+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:21:57.415+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:21:57.448+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.448+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:21:57.478+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.478+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:21:57.481+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.481+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:21:57.483+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.482+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:21:57.484+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:57.484+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:21:57.529+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.171 seconds
[2025-10-30T20:23:25.722+0000] {processor.py:186} INFO - Started process (PID=179366) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:23:25.725+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:23:25.729+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:23:25.772+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:23:25.806+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.806+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:23:25.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.839+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:23:25.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.843+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:23:25.845+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.844+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:23:25.846+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:25.846+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:23:25.887+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.176 seconds
[2025-10-30T20:24:58.929+0000] {processor.py:186} INFO - Started process (PID=179896) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:24:58.932+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:24:58.936+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:58.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:24:58.976+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:24:59.010+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:59.010+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:24:59.043+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:59.042+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:24:59.046+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:59.045+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:24:59.050+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:59.049+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:24:59.051+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:59.051+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:24:59.094+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.176 seconds
[2025-10-30T20:28:13.197+0000] {processor.py:186} INFO - Started process (PID=194994) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:28:13.200+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:28:13.204+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:28:13.251+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:28:13.292+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.291+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:28:13.336+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.336+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:28:13.341+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.341+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:28:13.343+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.343+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:28:13.346+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:13.345+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:28:13.402+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.219 seconds
[2025-10-30T20:29:50.399+0000] {processor.py:186} INFO - Started process (PID=195370) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:29:50.422+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:29:50.426+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:29:50.465+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:29:50.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.494+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:29:50.526+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.525+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:29:50.528+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.528+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:29:50.530+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.529+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:29:50.531+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:50.531+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:29:50.575+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.185 seconds
[2025-10-30T20:32:30.960+0000] {processor.py:186} INFO - Started process (PID=195988) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:32:30.963+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:32:30.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:32:31.006+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:32:31.039+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:31.039+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:32:31.070+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:31.070+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:32:31.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:31.073+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:32:31.076+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:31.075+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:32:31.078+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:31.078+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:32:31.124+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.173 seconds
[2025-10-30T20:33:50.269+0000] {processor.py:186} INFO - Started process (PID=196082) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:33:50.337+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:33:50.341+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:33:50.381+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:33:50.414+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.414+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:33:50.445+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:33:50.449+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.449+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:33:50.452+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.451+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:33:50.454+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:50.454+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:33:50.497+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.238 seconds
[2025-10-30T20:35:49.806+0000] {processor.py:186} INFO - Started process (PID=196488) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:35:49.842+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:35:49.845+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:35:49.883+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:35:49.915+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.915+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:35:49.946+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.946+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:35:49.949+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.949+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:35:49.951+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.951+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:35:49.953+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:49.953+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:35:49.994+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.197 seconds
[2025-10-30T20:38:12.087+0000] {processor.py:186} INFO - Started process (PID=197082) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:38:12.091+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:38:12.094+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:38:12.135+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:38:12.166+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.165+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:38:12.202+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.201+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:38:12.205+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.204+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:38:12.207+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.207+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:38:12.209+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:12.208+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:38:12.254+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.178 seconds
[2025-10-30T20:39:42.542+0000] {processor.py:186} INFO - Started process (PID=199268) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:39:42.545+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:39:42.550+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:39:42.587+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:39:42.621+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.621+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:39:42.666+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.666+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:39:42.670+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.670+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:39:42.672+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.672+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:39:42.674+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:42.674+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:39:42.744+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.213 seconds
[2025-10-30T20:41:28.859+0000] {processor.py:186} INFO - Started process (PID=199949) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:41:28.862+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:41:28.867+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:41:28.905+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:41:28.943+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.942+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:41:28.977+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.976+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:41:28.980+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.979+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:41:28.982+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.981+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:41:28.983+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:28.983+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:41:29.027+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.177 seconds
[2025-10-30T20:42:51.171+0000] {processor.py:186} INFO - Started process (PID=200107) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:42:51.174+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:42:51.177+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:42:51.216+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:42:51.250+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.249+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:42:51.281+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.280+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:42:51.285+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.285+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:42:51.288+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.287+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:42:51.289+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:51.289+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:42:51.328+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.166 seconds
[2025-10-30T20:44:05.360+0000] {processor.py:186} INFO - Started process (PID=200199) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:44:05.374+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:44:05.378+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:44:05.416+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:44:05.448+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.448+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:44:05.479+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.479+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:44:05.483+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.482+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:44:05.485+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.484+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:44:05.486+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:05.486+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:44:05.532+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.181 seconds
[2025-10-30T20:45:41.629+0000] {processor.py:186} INFO - Started process (PID=200461) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:45:41.631+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:45:41.635+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:45:41.673+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:45:41.702+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.702+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:45:41.734+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.734+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:45:41.737+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.737+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:45:41.739+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.739+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:45:41.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:41.741+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:45:41.784+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.166 seconds
[2025-10-30T20:47:03.037+0000] {processor.py:186} INFO - Started process (PID=200538) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:47:03.077+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:47:03.082+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:47:03.121+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:47:03.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.157+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:47:03.194+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.193+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:47:03.198+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.197+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:47:03.200+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.200+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:47:03.203+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:03.203+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:47:03.244+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.215 seconds
[2025-10-30T20:48:27.483+0000] {processor.py:186} INFO - Started process (PID=200680) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:48:27.498+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:48:27.502+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:48:27.541+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:48:27.572+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.571+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:48:27.602+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.601+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:48:27.604+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.604+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:48:27.606+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.605+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:48:27.609+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:27.609+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:48:27.652+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.178 seconds
[2025-10-30T20:49:43.608+0000] {processor.py:186} INFO - Started process (PID=200772) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:49:43.610+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:49:43.614+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:49:43.653+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:49:43.689+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.688+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:49:43.717+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.716+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:49:43.720+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.719+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:49:43.721+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.721+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:49:43.722+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:43.722+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:49:43.763+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.163 seconds
[2025-10-30T20:51:21.635+0000] {processor.py:186} INFO - Started process (PID=201015) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:51:21.638+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:51:21.641+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:51:21.681+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:51:21.712+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.712+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:51:21.743+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.743+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:51:21.746+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.746+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:51:21.748+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:51:21.750+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:21.749+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:51:21.793+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.167 seconds
[2025-10-30T20:52:37.546+0000] {processor.py:186} INFO - Started process (PID=201091) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:52:37.549+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:52:37.553+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:52:37.588+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:52:37.615+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.614+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:52:37.640+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.640+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:52:37.643+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.643+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:52:37.644+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.644+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:52:37.645+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:37.645+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:52:37.680+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.142 seconds
[2025-10-30T20:53:57.841+0000] {processor.py:186} INFO - Started process (PID=201249) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:53:57.843+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:53:57.847+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:53:57.881+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:53:57.908+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.907+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:53:57.933+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.933+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:53:57.936+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.936+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:53:57.938+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.937+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:53:57.939+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:57.939+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:53:57.973+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.140 seconds
[2025-10-30T20:55:31.486+0000] {processor.py:186} INFO - Started process (PID=201472) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:55:31.488+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:55:31.492+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:55:31.527+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:55:31.555+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.555+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:55:31.582+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:55:31.584+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:55:31.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:55:31.587+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:31.587+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:55:31.622+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.145 seconds
[2025-10-30T20:56:55.681+0000] {processor.py:186} INFO - Started process (PID=201554) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:56:55.684+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:56:55.687+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:56:55.720+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:56:55.745+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.745+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:56:55.770+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.770+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:56:55.773+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.773+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:56:55.774+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.774+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:56:55.776+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:55.775+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:56:55.810+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2025-10-30T20:58:05.376+0000] {processor.py:186} INFO - Started process (PID=201625) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:58:05.379+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:58:05.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:58:05.415+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:58:05.442+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.442+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:58:05.468+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.468+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:58:05.471+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.470+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:58:05.472+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.472+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:58:05.473+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:05.473+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:58:05.506+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.138 seconds
[2025-10-30T20:59:11.304+0000] {processor.py:186} INFO - Started process (PID=201711) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:59:11.306+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T20:59:11.309+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:59:11.343+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T20:59:11.370+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.370+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:59:11.396+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.396+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T20:59:11.400+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.399+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T20:59:11.401+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.401+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T20:59:11.402+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:11.402+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T20:59:11.436+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.140 seconds
[2025-10-30T21:00:34.811+0000] {processor.py:186} INFO - Started process (PID=201935) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:00:34.814+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:00:34.817+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:00:34.851+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:00:34.878+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.878+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:00:34.905+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.904+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:00:34.907+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.907+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:00:34.909+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.908+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:00:34.910+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:34.910+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:00:34.950+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.148 seconds
[2025-10-30T21:01:47.795+0000] {processor.py:186} INFO - Started process (PID=202009) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:01:47.797+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:01:47.800+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:01:47.833+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:01:47.859+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.859+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:01:47.884+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.884+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:01:47.887+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.887+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:01:47.888+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.888+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:01:47.889+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:47.889+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:01:47.924+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.138 seconds
[2025-10-30T21:03:00.624+0000] {processor.py:186} INFO - Started process (PID=202084) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:03:00.626+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:03:00.630+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:03:00.665+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:03:00.691+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.690+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:03:00.717+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.716+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:03:00.720+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.719+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:03:00.721+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.721+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:03:00.722+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:03:00.722+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:03:00.758+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.143 seconds
[2025-10-30T21:04:06.029+0000] {processor.py:186} INFO - Started process (PID=202169) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:04:06.047+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:04:06.050+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:04:06.083+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:04:06.110+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.109+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:04:06.135+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.135+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:04:06.138+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.138+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:04:06.139+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.139+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:04:06.140+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:06.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:04:06.175+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.155 seconds
[2025-10-30T21:05:31.132+0000] {processor.py:186} INFO - Started process (PID=202386) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:05:31.134+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:05:31.138+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:05:31.171+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:05:31.197+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.197+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:05:31.223+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:05:31.226+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.225+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:05:31.227+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.227+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:05:31.228+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:31.228+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:05:31.262+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.138 seconds
[2025-10-30T21:06:44.042+0000] {processor.py:186} INFO - Started process (PID=202458) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:06:44.044+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:06:44.047+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:06:44.081+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:06:44.114+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.113+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:06:44.141+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:06:44.143+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.143+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:06:44.145+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.144+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:06:44.146+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:44.146+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:06:44.182+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.150 seconds
[2025-10-30T21:07:53.088+0000] {processor.py:186} INFO - Started process (PID=202528) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:07:53.090+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:07:53.094+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:07:53.126+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:07:53.151+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.151+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:07:53.175+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.175+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:07:53.178+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.178+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:07:53.180+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.179+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:07:53.181+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:53.181+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:07:53.217+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2025-10-30T21:09:09.762+0000] {processor.py:186} INFO - Started process (PID=202621) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:09:09.765+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:09:09.768+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:09:09.802+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:09:09.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.827+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:09:09.853+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.853+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:09:09.856+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.856+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:09:09.857+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.857+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:09:09.859+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:09.858+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:09:09.893+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.138 seconds
[2025-10-30T21:10:34.854+0000] {processor.py:186} INFO - Started process (PID=202831) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:10:34.856+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:10:34.860+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:10:34.894+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:10:34.919+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.918+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:10:34.944+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.943+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:10:34.946+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.946+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:10:34.948+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.948+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:10:34.949+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:34.949+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:10:34.983+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2025-10-30T21:11:45.760+0000] {processor.py:186} INFO - Started process (PID=202904) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:11:45.763+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:11:45.766+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:11:45.801+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:11:45.830+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.829+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:11:45.855+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.854+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:11:45.857+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.857+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:11:45.859+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.858+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:11:45.860+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:45.860+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:11:45.894+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.142 seconds
[2025-10-30T21:12:59.413+0000] {processor.py:186} INFO - Started process (PID=202976) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:12:59.416+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:12:59.420+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:12:59.457+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:12:59.487+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.486+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:12:59.512+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.512+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:12:59.516+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.515+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:12:59.517+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.517+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:12:59.518+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:59.518+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:12:59.553+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.149 seconds
[2025-10-30T21:14:10.712+0000] {processor.py:186} INFO - Started process (PID=203070) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:14:10.723+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:14:10.727+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:14:10.762+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:14:10.793+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.793+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:14:10.822+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.822+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:14:10.825+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.825+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:14:10.827+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.826+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:14:10.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:10.828+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:14:10.864+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.159 seconds
[2025-10-30T21:15:33.633+0000] {processor.py:186} INFO - Started process (PID=203289) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:15:33.660+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:15:33.664+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:15:33.697+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:15:33.725+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.725+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:15:33.753+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.753+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:15:33.756+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.756+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:15:33.757+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.757+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:15:33.759+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.758+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:15:33.793+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.169 seconds
[2025-10-30T21:16:44.935+0000] {processor.py:186} INFO - Started process (PID=203362) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:16:44.937+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:16:44.941+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:16:44.974+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:16:45.000+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:45.000+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:16:45.026+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:45.025+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:16:45.029+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:45.029+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:16:45.030+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:45.030+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:16:45.031+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:45.031+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:16:45.067+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.141 seconds
[2025-10-30T21:17:53.883+0000] {processor.py:186} INFO - Started process (PID=203432) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:17:53.886+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:17:53.889+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:17:53.925+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:17:53.953+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.953+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:17:53.979+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.979+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:17:53.983+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.982+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:17:53.984+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.984+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:17:53.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:53.985+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:17:54.024+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.149 seconds
[2025-10-30T21:19:08.013+0000] {processor.py:186} INFO - Started process (PID=203521) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:19:08.016+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:19:08.019+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:19:08.054+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:19:08.081+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.080+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:19:08.107+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.107+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:19:08.110+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.110+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:19:08.112+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.111+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:19:08.113+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:08.113+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:19:08.148+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.143 seconds
[2025-10-30T21:20:30.984+0000] {processor.py:186} INFO - Started process (PID=203745) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:20:30.986+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:20:30.989+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:30.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:20:31.023+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:20:31.049+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:31.049+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:20:31.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:31.074+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:20:31.077+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:31.076+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:20:31.078+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:31.078+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:20:31.079+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:31.079+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:20:31.113+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2025-10-30T21:21:45.068+0000] {processor.py:186} INFO - Started process (PID=203821) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:21:45.070+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:21:45.074+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:21:45.108+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:21:45.133+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.132+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:21:45.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.158+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:21:45.161+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.160+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:21:45.162+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.162+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:21:45.163+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:45.163+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:21:45.198+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.138 seconds
[2025-10-30T21:23:00.473+0000] {processor.py:186} INFO - Started process (PID=203894) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:23:00.476+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:23:00.479+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:23:00.515+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:23:00.542+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.542+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:23:00.571+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.570+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:23:00.575+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.574+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:23:00.576+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.576+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:23:00.578+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:23:00.577+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:23:00.617+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.151 seconds
[2025-10-30T21:24:10.743+0000] {processor.py:186} INFO - Started process (PID=203986) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:24:10.745+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:24:10.749+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:24:10.782+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:24:10.810+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.809+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:24:10.837+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.837+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:24:10.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.840+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:24:10.841+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.841+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:24:10.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:10.842+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:24:10.878+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.144 seconds
[2025-10-30T21:25:39.770+0000] {processor.py:186} INFO - Started process (PID=204206) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:25:39.789+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:25:39.792+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:25:39.832+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:25:39.858+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.857+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:25:39.883+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.883+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:25:39.886+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.886+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:25:39.888+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.887+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:25:39.889+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:39.889+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:25:39.931+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.170 seconds
[2025-10-30T21:26:56.763+0000] {processor.py:186} INFO - Started process (PID=204281) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:26:56.766+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:26:56.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:26:56.805+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:26:56.831+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.831+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:26:56.858+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.858+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:26:56.861+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.861+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:26:56.862+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.862+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:26:56.864+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:56.864+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:26:56.901+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.146 seconds
[2025-10-30T21:28:07.280+0000] {processor.py:186} INFO - Started process (PID=204353) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:28:07.283+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:28:07.286+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:28:07.321+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:28:07.348+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.347+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:28:07.376+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.375+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:28:07.379+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.378+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:28:07.380+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.380+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:28:07.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:07.381+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:28:07.418+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.146 seconds
[2025-10-30T21:29:12.772+0000] {processor.py:186} INFO - Started process (PID=204440) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:29:12.775+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:29:12.781+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:29:12.831+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:29:12.863+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.862+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:29:12.889+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.889+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:29:12.892+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.892+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:29:12.894+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.893+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:29:12.895+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:12.895+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:29:12.938+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.179 seconds
[2025-10-30T21:30:41.078+0000] {processor.py:186} INFO - Started process (PID=204660) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:30:41.081+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:30:41.084+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:30:41.117+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:30:41.142+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.142+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:30:41.168+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.168+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:30:41.171+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.171+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:30:41.172+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.172+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:30:41.174+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:41.173+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:30:41.207+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2025-10-30T21:31:48.777+0000] {processor.py:186} INFO - Started process (PID=204730) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:31:48.780+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:31:48.783+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:31:48.818+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:31:48.848+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.848+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:31:48.874+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.873+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:31:48.876+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.876+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:31:48.878+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.877+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:31:48.881+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:48.880+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:31:48.916+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.147 seconds
[2025-10-30T21:33:01.660+0000] {processor.py:186} INFO - Started process (PID=204800) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:33:01.663+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:33:01.666+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:33:01.702+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:33:01.730+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.730+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:33:01.758+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.757+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:33:01.761+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.760+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:33:01.762+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.762+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:33:01.763+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:01.763+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:33:01.799+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.147 seconds
[2025-10-30T21:34:10.601+0000] {processor.py:186} INFO - Started process (PID=204890) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:34:10.604+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:34:10.607+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:34:10.642+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:34:10.669+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.668+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:34:10.694+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.693+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:34:10.697+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.696+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:34:10.698+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.698+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:34:10.699+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:10.699+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:34:10.740+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.146 seconds
[2025-10-30T21:35:35.870+0000] {processor.py:186} INFO - Started process (PID=205116) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:35:35.873+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:35:35.876+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:35:35.911+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:35:35.940+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.939+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:35:35.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.966+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:35:35.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:35:35.970+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.970+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:35:35.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:35.971+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:35:36.007+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.145 seconds
[2025-10-30T21:36:52.138+0000] {processor.py:186} INFO - Started process (PID=205248) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:36:52.140+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:36:52.144+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:36:52.178+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:36:52.207+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.206+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:36:52.235+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.235+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:36:52.238+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.238+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:36:52.240+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.240+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:36:52.241+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:52.241+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:36:52.277+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.147 seconds
[2025-10-30T21:38:01.691+0000] {processor.py:186} INFO - Started process (PID=205320) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:38:01.694+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:38:01.697+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:38:01.733+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:38:01.761+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.760+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:38:01.787+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.786+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:38:01.789+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.789+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:38:01.791+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.791+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:38:01.792+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.792+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:38:01.828+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.145 seconds
[2025-10-30T21:39:10.649+0000] {processor.py:186} INFO - Started process (PID=205407) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:39:10.652+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:39:10.655+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:39:10.689+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:39:10.717+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.717+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:39:10.744+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.744+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:39:10.747+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.747+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:39:10.749+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:39:10.750+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:10.750+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:39:10.785+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.144 seconds
[2025-10-30T21:40:41.417+0000] {processor.py:186} INFO - Started process (PID=205619) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:40:41.419+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:40:41.423+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:40:41.458+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:40:41.483+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.482+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:40:41.509+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.508+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:40:41.511+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.511+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:40:41.513+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.512+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:40:41.516+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.515+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:40:41.550+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.141 seconds
[2025-10-30T21:41:49.270+0000] {processor.py:186} INFO - Started process (PID=205689) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:41:49.273+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:41:49.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:41:49.310+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:41:49.336+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.336+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:41:49.362+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.361+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:41:49.364+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.364+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:41:49.366+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.365+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:41:49.367+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:49.367+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:41:49.402+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.141 seconds
[2025-10-30T21:43:00.174+0000] {processor.py:186} INFO - Started process (PID=205759) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:43:00.177+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:43:00.180+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:43:00.218+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:43:00.247+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.246+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:43:00.272+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.272+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:43:00.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.275+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:43:00.278+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.277+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:43:00.279+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:43:00.279+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:43:00.314+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.149 seconds
[2025-10-30T21:44:07.858+0000] {processor.py:186} INFO - Started process (PID=205847) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:44:07.861+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:44:07.864+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:44:07.900+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:44:07.929+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.928+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:44:07.962+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.961+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:44:07.965+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.964+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:44:07.966+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.966+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:44:07.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:07.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:44:08.007+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.157 seconds
[2025-10-30T21:45:31.044+0000] {processor.py:186} INFO - Started process (PID=206030) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:45:31.047+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:45:31.051+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:45:31.085+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:45:31.111+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.111+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:45:31.138+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.138+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:45:31.141+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:45:31.142+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.142+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:45:31.143+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:31.143+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:45:31.178+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.142 seconds
[2025-10-30T21:46:45.491+0000] {processor.py:186} INFO - Started process (PID=206106) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:46:45.493+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:46:45.497+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:46:45.530+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:46:45.556+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.555+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:46:45.581+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:46:45.584+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.583+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:46:45.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.585+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:46:45.588+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:45.588+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:46:45.625+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.142 seconds
[2025-10-30T21:47:56.085+0000] {processor.py:186} INFO - Started process (PID=206177) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:47:56.087+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:47:56.091+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:47:56.125+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:47:56.150+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.150+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:47:56.176+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.176+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:47:56.179+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.178+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:47:56.180+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.180+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:47:56.181+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:56.181+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:47:56.216+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.139 seconds
[2025-10-30T21:49:13.445+0000] {processor.py:186} INFO - Started process (PID=206253) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:49:13.448+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-10-30T21:49:13.452+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:49:13.488+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-10-30T21:49:13.518+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.518+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:49:13.546+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.546+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-10-30T21:49:13.549+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.549+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-10-30T21:49:13.550+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.550+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-10-30T21:49:13.552+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:13.552+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-10-30T21:49:13.588+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.152 seconds
