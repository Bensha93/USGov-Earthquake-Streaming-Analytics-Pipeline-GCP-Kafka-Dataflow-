[2025-10-30T20:01:23.687+0000] {processor.py:186} INFO - Started process (PID=165378) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:01:23.688+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:01:23.693+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:23.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:01:23.724+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:01:23.903+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:23.902+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:23.927+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:23.926+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:23.948+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:23.948+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:23.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:23.985+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:24.006+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.005+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:24.026+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.025+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:24.043+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.042+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:24.083+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.082+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.102+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.101+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.125+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.124+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.161+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.160+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.181+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.180+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.199+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.199+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.220+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.219+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.259+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.259+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.280+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.280+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.302+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.302+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.338+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.338+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.359+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.358+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.379+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.379+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.396+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.395+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.436+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.435+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.455+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.454+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.476+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.475+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.505+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.505+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.524+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.523+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.546+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.546+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.563+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.563+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.564+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.563+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:01:24.584+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.584+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer_with_no_taskflow
[2025-10-30T20:01:24.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.585+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer_with_no_taskflow
[2025-10-30T20:01:24.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.585+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer_with_no_taskflow
[2025-10-30T20:01:24.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.586+0000] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer_with_no_taskflow
[2025-10-30T20:01:24.599+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.599+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:01:24.600+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.600+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:01:24.601+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.601+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:01:24.602+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:01:24.601+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:01:24.710+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 1.032 seconds
[2025-10-30T20:02:54.434+0000] {processor.py:186} INFO - Started process (PID=165964) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:02:54.436+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:02:54.441+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:02:54.528+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:02:54.560+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.559+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:02:54.593+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:02:54.596+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.596+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:02:54.597+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.597+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:02:54.599+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:02:54.599+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:02:54.643+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.218 seconds
[2025-10-30T20:04:11.684+0000] {processor.py:186} INFO - Started process (PID=166444) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:04:11.687+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:04:11.691+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:04:11.725+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:04:11.761+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.761+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:04:11.792+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.792+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:04:11.796+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.796+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:04:11.799+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.798+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:04:11.801+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:04:11.800+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:04:11.844+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.168 seconds
[2025-10-30T20:05:35.648+0000] {processor.py:186} INFO - Started process (PID=167018) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:05:35.651+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:05:35.655+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:05:35.695+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:05:35.730+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.729+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:05:35.759+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.759+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:05:35.763+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.763+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:05:35.766+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.765+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:05:35.768+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:05:35.768+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:05:35.816+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.178 seconds
[2025-10-30T20:07:19.735+0000] {processor.py:186} INFO - Started process (PID=167454) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:07:19.738+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:07:19.741+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:07:19.778+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:07:19.809+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.808+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:07:19.838+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.838+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:07:19.842+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.841+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:07:19.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.843+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:07:19.845+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:07:19.845+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:07:19.890+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.165 seconds
[2025-10-30T20:08:37.883+0000] {processor.py:186} INFO - Started process (PID=170056) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:08:37.919+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:08:37.923+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:37.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:08:37.962+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:08:37.995+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:37.994+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:08:38.030+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:38.029+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:08:38.033+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:38.032+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:08:38.034+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:38.034+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:08:38.035+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:08:38.035+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:08:38.079+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.204 seconds
[2025-10-30T20:09:57.276+0000] {processor.py:186} INFO - Started process (PID=170389) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:09:57.278+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:09:57.282+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:09:57.317+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:09:57.348+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.347+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:09:57.377+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.377+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:09:57.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.381+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:09:57.383+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.383+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:09:57.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:09:57.385+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:09:57.425+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.159 seconds
[2025-10-30T20:11:22.356+0000] {processor.py:186} INFO - Started process (PID=170596) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:11:22.392+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:11:22.395+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:11:22.428+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:11:22.456+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.456+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:11:22.485+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.485+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:11:22.488+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.488+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:11:22.489+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.489+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:11:22.490+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:11:22.490+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:11:22.532+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.188 seconds
[2025-10-30T20:12:33.160+0000] {processor.py:186} INFO - Started process (PID=170667) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:12:33.163+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:12:33.167+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:12:33.206+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:12:33.237+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.236+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:12:33.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.275+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:12:33.280+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.279+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:12:33.281+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.281+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:12:33.283+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:12:33.282+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:12:33.340+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.191 seconds
[2025-10-30T20:13:46.661+0000] {processor.py:186} INFO - Started process (PID=170740) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:13:46.664+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:13:46.667+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:13:46.702+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:13:46.732+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.732+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:13:46.762+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.762+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:13:46.765+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.765+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:13:46.767+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.767+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:13:46.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:13:46.768+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:13:46.808+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.158 seconds
[2025-10-30T20:14:55.120+0000] {processor.py:186} INFO - Started process (PID=170811) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:14:55.123+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:14:55.126+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:14:55.163+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:14:55.193+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.193+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:14:55.227+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.227+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:14:55.230+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.230+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:14:55.231+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.231+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:14:55.233+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:14:55.232+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:14:55.277+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.168 seconds
[2025-10-30T20:16:34.861+0000] {processor.py:186} INFO - Started process (PID=171303) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:16:34.863+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:16:34.867+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:16:34.904+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:16:34.932+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.932+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:16:34.964+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.963+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:16:34.967+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.966+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:16:34.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:16:34.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:16:34.969+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:16:35.016+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.169 seconds
[2025-10-30T20:17:53.074+0000] {processor.py:186} INFO - Started process (PID=171378) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:17:53.076+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:17:53.079+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:17:53.119+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:17:53.149+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.149+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:17:53.183+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.183+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:17:53.186+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.186+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:17:53.188+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.187+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:17:53.189+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:17:53.189+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:17:53.230+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.171 seconds
[2025-10-30T20:19:43.415+0000] {processor.py:186} INFO - Started process (PID=171862) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:19:43.417+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:19:43.421+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:19:43.459+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:19:43.490+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.490+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:19:43.524+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.524+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:19:43.528+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.527+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:19:43.529+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.529+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:19:43.530+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:19:43.530+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:19:43.570+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.166 seconds
[2025-10-30T20:21:56.045+0000] {processor.py:186} INFO - Started process (PID=172917) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:21:56.048+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:21:56.053+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:21:56.097+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:21:56.129+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.128+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:21:56.162+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.162+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:21:56.166+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.165+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:21:56.167+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.167+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:21:56.168+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:21:56.168+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:21:56.210+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.177 seconds
[2025-10-30T20:23:24.374+0000] {processor.py:186} INFO - Started process (PID=179338) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:23:24.378+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:23:24.382+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:23:24.419+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:23:24.450+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.450+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:23:24.488+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.488+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:23:24.493+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.492+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:23:24.494+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.494+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:23:24.496+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:23:24.495+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:23:24.540+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.176 seconds
[2025-10-30T20:24:57.727+0000] {processor.py:186} INFO - Started process (PID=179895) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:24:57.757+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:24:57.762+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:24:57.799+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:24:57.832+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.831+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:24:57.862+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.862+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:24:57.867+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.866+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:24:57.871+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.871+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:24:57.873+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:24:57.872+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:24:57.916+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.199 seconds
[2025-10-30T20:28:11.401+0000] {processor.py:186} INFO - Started process (PID=194878) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:28:11.447+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:28:11.454+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:28:11.552+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:28:11.649+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.648+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:28:11.738+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.738+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:28:11.749+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:28:11.755+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.754+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:28:11.761+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:28:11.760+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:28:11.852+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.475 seconds
[2025-10-30T20:29:49.026+0000] {processor.py:186} INFO - Started process (PID=195369) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:29:49.029+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:29:49.032+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:29:49.071+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:29:49.104+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.104+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:29:49.133+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.133+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:29:49.136+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.136+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:29:49.138+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.138+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:29:49.140+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:29:49.140+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:29:49.179+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.164 seconds
[2025-10-30T20:32:29.916+0000] {processor.py:186} INFO - Started process (PID=195987) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:32:29.941+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:32:29.946+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:29.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:32:29.987+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:32:30.020+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.019+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:32:30.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.055+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:32:30.058+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.058+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:32:30.059+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.059+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:32:30.061+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:32:30.060+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:32:30.111+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.205 seconds
[2025-10-30T20:33:48.914+0000] {processor.py:186} INFO - Started process (PID=196081) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:33:48.916+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:33:48.920+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:48.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:33:48.958+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:33:48.990+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:48.990+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:33:49.021+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:49.020+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:33:49.023+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:49.023+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:33:49.024+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:49.024+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:33:49.026+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:33:49.026+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:33:49.068+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.165 seconds
[2025-10-30T20:35:48.433+0000] {processor.py:186} INFO - Started process (PID=196487) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:35:48.454+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:35:48.457+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:35:48.498+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:35:48.530+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.529+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:35:48.563+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.563+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:35:48.566+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.566+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:35:48.568+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.568+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:35:48.571+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:35:48.571+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:35:48.616+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.192 seconds
[2025-10-30T20:38:10.764+0000] {processor.py:186} INFO - Started process (PID=197081) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:38:10.779+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:38:10.784+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:38:10.824+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:38:10.858+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.858+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:38:10.891+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.891+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:38:10.895+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.894+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:38:10.896+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.896+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:38:10.897+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:38:10.897+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:38:10.942+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.188 seconds
[2025-10-30T20:39:41.204+0000] {processor.py:186} INFO - Started process (PID=199267) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:39:41.206+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:39:41.210+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:39:41.251+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:39:41.282+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.282+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:39:41.312+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.312+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:39:41.315+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.315+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:39:41.317+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.316+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:39:41.318+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:39:41.317+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:39:41.364+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.170 seconds
[2025-10-30T20:41:27.439+0000] {processor.py:186} INFO - Started process (PID=199948) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:41:27.497+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:41:27.502+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:41:27.541+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:41:27.574+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.574+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:41:27.607+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.607+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:41:27.610+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.610+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:41:27.612+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.612+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:41:27.613+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:41:27.613+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:41:27.655+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.226 seconds
[2025-10-30T20:42:49.876+0000] {processor.py:186} INFO - Started process (PID=200106) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:42:49.880+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:42:49.884+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:42:49.924+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:42:49.954+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.953+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:42:49.985+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.985+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:42:49.988+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.988+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:42:49.990+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.989+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:42:49.991+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:42:49.990+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:42:50.031+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.164 seconds
[2025-10-30T20:44:04.060+0000] {processor.py:186} INFO - Started process (PID=200198) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:44:04.088+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:44:04.092+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:44:04.128+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:44:04.159+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.159+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:44:04.191+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.190+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:44:04.194+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.193+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:44:04.195+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.195+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:44:04.196+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:44:04.196+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:44:04.238+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.189 seconds
[2025-10-30T20:45:40.321+0000] {processor.py:186} INFO - Started process (PID=200460) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:45:40.324+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:45:40.327+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:45:40.369+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:45:40.402+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.401+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:45:40.435+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.434+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:45:40.437+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.437+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:45:40.439+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.438+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:45:40.441+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:45:40.440+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:45:40.480+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.169 seconds
[2025-10-30T20:47:01.724+0000] {processor.py:186} INFO - Started process (PID=200537) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:47:01.726+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:47:01.730+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:47:01.770+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:47:01.801+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.801+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:47:01.835+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.835+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:47:01.838+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.837+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:47:01.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.839+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:47:01.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:47:01.840+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:47:01.878+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.164 seconds
[2025-10-30T20:48:26.849+0000] {processor.py:186} INFO - Started process (PID=200679) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:48:26.853+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:48:26.856+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:48:26.898+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:48:26.929+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.929+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:48:26.965+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.965+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:48:26.968+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:48:26.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.969+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:48:26.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:48:26.970+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:48:27.022+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.183 seconds
[2025-10-30T20:49:42.281+0000] {processor.py:186} INFO - Started process (PID=200771) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:49:42.305+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:49:42.309+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:49:42.345+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:49:42.376+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.375+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:49:42.405+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.405+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:49:42.410+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.410+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:49:42.413+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.412+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:49:42.414+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:49:42.414+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:49:42.455+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.182 seconds
[2025-10-30T20:51:20.324+0000] {processor.py:186} INFO - Started process (PID=201014) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:51:20.327+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:51:20.331+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:51:20.368+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:51:20.398+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.397+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:51:20.426+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.426+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:51:20.429+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.429+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:51:20.431+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.431+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:51:20.433+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:51:20.433+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:51:20.474+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.158 seconds
[2025-10-30T20:52:36.652+0000] {processor.py:186} INFO - Started process (PID=201090) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:52:36.654+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:52:36.658+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:52:36.690+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:52:36.716+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.716+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:52:36.743+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.742+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:52:36.745+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.745+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:52:36.747+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.746+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:52:36.748+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:52:36.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:52:36.783+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.140 seconds
[2025-10-30T20:53:56.568+0000] {processor.py:186} INFO - Started process (PID=201248) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:53:56.570+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:53:56.574+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:53:56.606+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:53:56.632+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.632+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:53:56.657+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.656+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:53:56.659+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.659+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:53:56.661+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.660+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:53:56.662+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:53:56.661+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:53:56.698+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.141 seconds
[2025-10-30T20:55:30.208+0000] {processor.py:186} INFO - Started process (PID=201471) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:55:30.230+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:55:30.234+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:55:30.266+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:55:30.293+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.293+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:55:30.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.320+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:55:30.323+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.323+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:55:30.325+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.325+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:55:30.327+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:55:30.326+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:55:30.362+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.163 seconds
[2025-10-30T20:56:54.399+0000] {processor.py:186} INFO - Started process (PID=201553) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:56:54.401+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:56:54.405+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:56:54.441+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:56:54.469+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.468+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:56:54.495+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.495+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:56:54.498+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.497+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:56:54.499+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.499+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:56:54.500+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:56:54.500+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:56:54.534+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.144 seconds
[2025-10-30T20:58:04.083+0000] {processor.py:186} INFO - Started process (PID=201624) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:58:04.086+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:58:04.090+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:58:04.127+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:58:04.155+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.155+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:58:04.185+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.185+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:58:04.189+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.189+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:58:04.190+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.190+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:58:04.191+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:58:04.191+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:58:04.226+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.152 seconds
[2025-10-30T20:59:10.027+0000] {processor.py:186} INFO - Started process (PID=201710) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:59:10.030+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T20:59:10.034+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:59:10.066+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T20:59:10.095+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.095+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T20:59:10.122+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.122+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:59:10.125+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.125+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:59:10.127+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.127+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T20:59:10.128+0000] {logging_mixin.py:190} INFO - [2025-10-30T20:59:10.128+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T20:59:10.165+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.147 seconds
[2025-10-30T21:00:33.529+0000] {processor.py:186} INFO - Started process (PID=201934) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:00:33.540+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:00:33.543+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:00:33.576+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:00:33.602+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.602+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:00:33.628+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.628+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:00:33.631+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.631+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:00:33.632+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.632+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:00:33.633+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:00:33.633+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:00:33.671+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.150 seconds
[2025-10-30T21:01:46.515+0000] {processor.py:186} INFO - Started process (PID=202008) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:01:46.517+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:01:46.520+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:01:46.552+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:01:46.580+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.580+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:01:46.607+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.606+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:01:46.609+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.609+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:01:46.611+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.611+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:01:46.612+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:01:46.612+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:01:46.646+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.139 seconds
[2025-10-30T21:02:59.344+0000] {processor.py:186} INFO - Started process (PID=202083) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:02:59.347+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:02:59.350+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:02:59.384+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:02:59.409+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.409+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:02:59.434+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.434+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:02:59.437+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.437+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:02:59.439+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.438+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:02:59.440+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:02:59.440+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:02:59.478+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.142 seconds
[2025-10-30T21:04:04.753+0000] {processor.py:186} INFO - Started process (PID=202168) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:04:04.755+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:04:04.758+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:04:04.789+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:04:04.815+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.815+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:04:04.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.840+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:04:04.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.843+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:04:04.844+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.844+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:04:04.845+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:04:04.845+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:04:04.878+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.134 seconds
[2025-10-30T21:05:30.779+0000] {processor.py:186} INFO - Started process (PID=202385) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:05:30.796+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:05:30.800+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:05:30.833+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:05:30.858+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.858+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:05:30.885+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.884+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:05:30.887+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.887+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:05:30.889+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.888+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:05:30.890+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:05:30.890+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:05:30.925+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.154 seconds
[2025-10-30T21:06:42.763+0000] {processor.py:186} INFO - Started process (PID=202457) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:06:42.766+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:06:42.770+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:06:42.814+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:06:42.839+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.839+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:06:42.870+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.870+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:06:42.873+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.873+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:06:42.874+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.874+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:06:42.875+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:06:42.875+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:06:42.910+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.159 seconds
[2025-10-30T21:07:51.787+0000] {processor.py:186} INFO - Started process (PID=202527) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:07:51.790+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:07:51.793+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:07:51.825+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:07:51.850+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.850+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:07:51.876+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.875+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:07:51.878+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.878+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:07:51.879+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.879+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:07:51.880+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:07:51.880+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:07:51.917+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.138 seconds
[2025-10-30T21:09:08.484+0000] {processor.py:186} INFO - Started process (PID=202620) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:09:08.489+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:09:08.493+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:09:08.527+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:09:08.553+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.553+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:09:08.579+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.579+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:09:08.582+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:09:08.583+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.583+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:09:08.584+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:09:08.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:09:08.619+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.144 seconds
[2025-10-30T21:10:33.578+0000] {processor.py:186} INFO - Started process (PID=202830) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:10:33.601+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:10:33.604+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:10:33.636+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:10:33.662+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.662+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:10:33.687+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.687+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:10:33.690+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.690+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:10:33.691+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.691+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:10:33.692+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:10:33.692+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:10:33.726+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.156 seconds
[2025-10-30T21:11:44.480+0000] {processor.py:186} INFO - Started process (PID=202903) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:11:44.482+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:11:44.485+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:11:44.516+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:11:44.542+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.542+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:11:44.568+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.567+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:11:44.570+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.570+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:11:44.572+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.571+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:11:44.573+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:11:44.573+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:11:44.607+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.135 seconds
[2025-10-30T21:12:58.129+0000] {processor.py:186} INFO - Started process (PID=202975) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:12:58.132+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:12:58.135+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:12:58.167+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:12:58.194+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.194+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:12:58.222+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:12:58.225+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.224+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:12:58.226+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.226+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:12:58.227+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:12:58.227+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:12:58.261+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.140 seconds
[2025-10-30T21:14:09.428+0000] {processor.py:186} INFO - Started process (PID=203069) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:14:09.431+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:14:09.434+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:14:09.467+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:14:09.495+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.495+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:14:09.523+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.523+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:14:09.526+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.526+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:14:09.528+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.527+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:14:09.529+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:14:09.529+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:14:09.565+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.145 seconds
[2025-10-30T21:15:33.063+0000] {processor.py:186} INFO - Started process (PID=203288) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:15:33.065+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:15:33.069+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:15:33.102+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:15:33.127+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.127+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:15:33.154+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.153+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:15:33.156+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.156+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:15:33.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.157+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:15:33.159+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:15:33.159+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:15:33.194+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.139 seconds
[2025-10-30T21:16:44.623+0000] {processor.py:186} INFO - Started process (PID=203361) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:16:44.639+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:16:44.642+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:16:44.676+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:16:44.703+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.703+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:16:44.731+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.730+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:16:44.734+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.733+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:16:44.735+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.735+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:16:44.736+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:16:44.736+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:16:44.773+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.157 seconds
[2025-10-30T21:17:52.572+0000] {processor.py:186} INFO - Started process (PID=203429) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:17:52.589+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:17:52.592+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:17:52.625+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:17:52.649+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.649+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:17:52.678+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.677+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:17:52.681+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.680+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:17:52.682+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.682+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:17:52.683+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:17:52.683+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:17:52.723+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.160 seconds
[2025-10-30T21:19:06.723+0000] {processor.py:186} INFO - Started process (PID=203520) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:19:06.726+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:19:06.729+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:19:06.762+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:19:06.790+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.790+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:19:06.817+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.817+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:19:06.820+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.819+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:19:06.821+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.821+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:19:06.822+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:19:06.822+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:19:06.859+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.144 seconds
[2025-10-30T21:20:29.703+0000] {processor.py:186} INFO - Started process (PID=203744) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:20:29.706+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:20:29.710+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:20:29.746+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:20:29.774+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.774+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:20:29.800+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.800+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:20:29.804+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.803+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:20:29.805+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.805+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:20:29.806+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:20:29.806+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:20:29.842+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.147 seconds
[2025-10-30T21:21:43.752+0000] {processor.py:186} INFO - Started process (PID=203820) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:21:43.754+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:21:43.757+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:21:43.788+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:21:43.812+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.812+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:21:43.838+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.837+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:21:43.840+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.840+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:21:43.842+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.841+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:21:43.843+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:21:43.843+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:21:43.878+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.134 seconds
[2025-10-30T21:22:59.198+0000] {processor.py:186} INFO - Started process (PID=203893) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:22:59.201+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:22:59.204+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:22:59.237+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:22:59.262+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.262+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:22:59.291+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.291+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:22:59.294+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.294+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:22:59.295+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.295+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:22:59.297+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:22:59.296+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:22:59.332+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.142 seconds
[2025-10-30T21:24:09.445+0000] {processor.py:186} INFO - Started process (PID=203985) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:24:09.462+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:24:09.465+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:24:09.497+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:24:09.523+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.523+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:24:09.552+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.551+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:24:09.555+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.555+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:24:09.556+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.556+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:24:09.557+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:24:09.557+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:24:09.592+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.156 seconds
[2025-10-30T21:25:38.491+0000] {processor.py:186} INFO - Started process (PID=204205) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:25:38.493+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:25:38.496+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:25:38.531+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:25:38.559+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.558+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:25:38.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:25:38.587+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.587+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:25:38.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.588+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:25:38.590+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:25:38.590+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:25:38.628+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.146 seconds
[2025-10-30T21:26:55.487+0000] {processor.py:186} INFO - Started process (PID=204280) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:26:55.489+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:26:55.493+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:26:55.529+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:26:55.556+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.556+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:26:55.582+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:26:55.584+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:26:55.585+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.585+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:26:55.587+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:26:55.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:26:55.622+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.143 seconds
[2025-10-30T21:28:06.425+0000] {processor.py:186} INFO - Started process (PID=204352) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:28:06.428+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:28:06.431+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:28:06.465+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:28:06.492+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.492+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:28:06.517+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.517+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:28:06.520+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.520+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:28:06.521+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.521+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:28:06.523+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:28:06.522+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:28:06.561+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.144 seconds
[2025-10-30T21:29:11.480+0000] {processor.py:186} INFO - Started process (PID=204439) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:29:11.499+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:29:11.502+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:29:11.534+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:29:11.561+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.560+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:29:11.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:29:11.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.589+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:29:11.591+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.591+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:29:11.593+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:29:11.592+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:29:11.627+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.157 seconds
[2025-10-30T21:30:39.803+0000] {processor.py:186} INFO - Started process (PID=204659) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:30:39.806+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:30:39.810+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:30:39.843+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:30:39.869+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.869+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:30:39.895+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.895+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:30:39.898+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.898+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:30:39.899+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.899+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:30:39.900+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:30:39.900+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:30:39.936+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.141 seconds
[2025-10-30T21:31:47.493+0000] {processor.py:186} INFO - Started process (PID=204729) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:31:47.496+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:31:47.499+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:31:47.532+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:31:47.560+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.559+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:31:47.586+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.586+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:31:47.589+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.589+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:31:47.590+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.590+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:31:47.591+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:31:47.591+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:31:47.631+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.146 seconds
[2025-10-30T21:33:00.368+0000] {processor.py:186} INFO - Started process (PID=204799) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:33:00.371+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:33:00.375+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:33:00.413+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:33:00.440+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.440+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:33:00.465+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.465+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:33:00.468+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.468+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:33:00.469+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.469+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:33:00.471+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:33:00.470+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:33:00.505+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.147 seconds
[2025-10-30T21:34:09.323+0000] {processor.py:186} INFO - Started process (PID=204889) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:34:09.326+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:34:09.329+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:34:09.363+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:34:09.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.390+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:34:09.415+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.414+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:34:09.418+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.417+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:34:09.419+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.419+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:34:09.420+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:34:09.420+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:34:09.458+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.143 seconds
[2025-10-30T21:35:34.592+0000] {processor.py:186} INFO - Started process (PID=205113) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:35:34.608+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:35:34.612+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:35:34.643+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:35:34.673+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.672+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:35:34.701+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.701+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:35:34.704+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.704+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:35:34.705+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.705+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:35:34.706+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:35:34.706+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:35:34.741+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.157 seconds
[2025-10-30T21:36:50.857+0000] {processor.py:186} INFO - Started process (PID=205247) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:36:50.860+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:36:50.863+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:36:50.895+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:36:50.920+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.920+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:36:50.949+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.949+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:36:50.952+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.952+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:36:50.953+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.953+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:36:50.954+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:36:50.954+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:36:50.998+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.148 seconds
[2025-10-30T21:38:00.882+0000] {processor.py:186} INFO - Started process (PID=205319) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:38:00.899+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:38:00.903+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:00.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:38:00.937+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:38:00.965+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:00.964+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:38:00.993+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:00.993+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:38:00.997+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:00.997+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:38:00.999+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:00.998+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:38:01.000+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:38:01.000+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:38:01.045+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.171 seconds
[2025-10-30T21:39:09.346+0000] {processor.py:186} INFO - Started process (PID=205406) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:39:09.349+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:39:09.353+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:39:09.388+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:39:09.415+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.414+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:39:09.441+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.441+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:39:09.444+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.444+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:39:09.445+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:39:09.447+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:39:09.446+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:39:09.481+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.143 seconds
[2025-10-30T21:40:41.060+0000] {processor.py:186} INFO - Started process (PID=205618) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:40:41.063+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:40:41.067+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:40:41.098+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:40:41.123+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.123+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:40:41.150+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.150+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:40:41.153+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.153+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:40:41.155+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.154+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:40:41.157+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:40:41.157+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:40:41.192+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.140 seconds
[2025-10-30T21:41:47.991+0000] {processor.py:186} INFO - Started process (PID=205688) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:41:47.994+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:41:47.997+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:47.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:41:48.029+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:41:48.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:48.055+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:41:48.080+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:48.080+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:41:48.083+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:48.083+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:41:48.084+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:48.084+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:41:48.085+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:41:48.085+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:41:48.119+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.136 seconds
[2025-10-30T21:42:58.890+0000] {processor.py:186} INFO - Started process (PID=205758) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:42:58.893+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:42:58.897+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:42:58.931+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:42:58.960+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.960+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:42:58.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.986+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:42:58.989+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.989+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:42:58.990+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.990+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:42:58.992+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:42:58.992+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:42:59.028+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.146 seconds
[2025-10-30T21:44:06.574+0000] {processor.py:186} INFO - Started process (PID=205844) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:44:06.577+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:44:06.580+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:44:06.613+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:44:06.639+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.639+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:44:06.665+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.664+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:44:06.668+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.668+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:44:06.669+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.669+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:44:06.671+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:44:06.671+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:44:06.707+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.141 seconds
[2025-10-30T21:45:30.673+0000] {processor.py:186} INFO - Started process (PID=206029) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:45:30.675+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:45:30.679+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:45:30.712+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:45:30.742+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.741+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:45:30.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.768+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:45:30.771+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.771+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:45:30.773+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.773+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:45:30.774+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:45:30.774+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:45:30.809+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.145 seconds
[2025-10-30T21:46:44.196+0000] {processor.py:186} INFO - Started process (PID=206105) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:46:44.199+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:46:44.203+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:46:44.236+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:46:44.264+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.263+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:46:44.294+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.294+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:46:44.298+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.298+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:46:44.299+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.299+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:46:44.301+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:46:44.300+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:46:44.337+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.148 seconds
[2025-10-30T21:47:54.797+0000] {processor.py:186} INFO - Started process (PID=206176) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:47:54.799+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:47:54.803+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:47:54.837+0000] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:47:54.864+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.863+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:47:54.890+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.890+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:47:54.893+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.893+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:47:54.894+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.894+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:47:54.896+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:47:54.896+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:47:54.933+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.144 seconds
[2025-10-30T21:49:12.158+0000] {processor.py:186} INFO - Started process (PID=206252) to work on /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:49:12.161+0000] {processor.py:914} INFO - Processing file /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-10-30T21:49:12.165+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:49:12.199+0000] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-10-30T21:49:12.226+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.226+0000] {dag.py:3239} INFO - Sync 4 DAGs
[2025-10-30T21:49:12.255+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.254+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:49:12.258+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.258+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:49:12.259+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.259+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-10-30T21:49:12.261+0000] {logging_mixin.py:190} INFO - [2025-10-30T21:49:12.260+0000] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-10-30T21:49:12.298+0000] {processor.py:208} INFO - Processing /home/bensha02019/USGov-Earthquake-Streaming-Analytics-Pipeline-GCP-Kafka-Dataflow-/venv/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.148 seconds
